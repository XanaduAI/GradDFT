{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Functionals\n",
    "\n",
    "In this tutorial, we will cover how to create a parameterized neural functional. This will be a modified version of the workflow from `~/examples/basic_notebooks/example_lda_functional_02.ipynb` where the coefficient function $\\mathbf{c}_{\\boldsymbol{\\theta}}[\\rho](\\mathbf{r})$ is no longer a constant but takes the form of a basic neural network.\n",
    "\n",
    "Like before, we begin by performing a PySCF calculation, this time looking at $\\text{H}_2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablo.casares/miniforge3/envs/graddft/lib/python3.10/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting \"B3LYP_WITH_VWN5 = True\" in pyscf_conf.py\n",
      "  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pablo.casares/miniforge3/envs/graddft/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "converged SCF energy = -1.11599939445016  <S^2> = 4.4408921e-16  2S+1 = 1\n"
     ]
    }
   ],
   "source": [
    "from pyscf import gto, dft\n",
    "import grad_dft as gd\n",
    "\n",
    "# Define the geometry of the molecule\n",
    "mol = gto.M(atom=[[\"H\", (0, 0, 0)], [\"H\", (0, 0, 1)]], basis=\"def2-tzvp\", charge=0, spin=0)\n",
    "mf = dft.UKS(mol)\n",
    "ground_truth_energy = mf.kernel()\n",
    "\n",
    "# Then we can use the following function to generate the molecule object\n",
    "HH_molecule = gd.molecule_from_pyscf(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create an instance of `NeuralFunctional`. You will recognize the ingredients from when we built a basic `Functional` in `~/examples/basic_notebooks/example_lda_functional_02.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def coefficient_inputs(molecule: gd.Molecule, *_, **__):\n",
    "    rho = molecule.density()\n",
    "    kinetic = molecule.kinetic_density()\n",
    "    return jnp.concatenate((rho, kinetic), axis = 1)\n",
    "\n",
    "def energy_densities(molecule: gd.Molecule, clip_cte: float = 1e-30, *_, **__):\n",
    "    r\"\"\"Auxiliary function to generate the features of LSDA.\"\"\"\n",
    "    # Molecule can compute the density matrix.\n",
    "    rho = jnp.clip(molecule.density(), a_min=clip_cte)\n",
    "    # Now we can implement the LDA energy density equation in the paper.\n",
    "    lda_e = -3/2 * (3/(4*jnp.pi)) ** (1/3) * (rho**(4/3)).sum(axis = 1, keepdims = True)\n",
    "    # For simplicity we do not include the exchange polarization correction\n",
    "    # check function exchange_polarization_correction in functional.py\n",
    "    # The output of features must be an Array of dimension n_grid x n_features.\n",
    "    return lda_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, however, the coefficient function is a simple neural network created with `flax` and `jax.nn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "from jax.nn import sigmoid\n",
    "\n",
    "out_features = 1\n",
    "def coefficients(instance, rhoinputs):\n",
    "    r\"\"\"\n",
    "    Instance is an instance of the class Functional or NeuralFunctional.\n",
    "    rhoinputs is the input to the neural network, in the form of an array.\n",
    "    localfeatures represents the potentials e_\\theta(r).\n",
    "\n",
    "    The output of this function is the energy density of the system.\n",
    "    \"\"\"\n",
    "\n",
    "    x = nn.Dense(features=out_features)(rhoinputs)\n",
    "    x = nn.LayerNorm()(x)\n",
    "    return sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now create a `NeuralFunctional` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = gd.NeuralFunctional(coefficients, energy_densities, coefficient_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should I now initialize `nf` with some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.random import PRNGKey\n",
    "\n",
    "key = PRNGKey(42)\n",
    "cinputs = coefficient_inputs(HH_molecule)\n",
    "params = nf.init(key, cinputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can calculate the total energy given these functional parameters in the same way as we did for a regular `Functional` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural functional energy with random parameters is -0.7769992\n"
     ]
    }
   ],
   "source": [
    "E = nf.energy(params, HH_molecule)\n",
    "print(\"Neural functional energy with random parameters is\", E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complicated `NeuralFunctional`s will be defined in the `intermediate_notebooks` and `advanced_scripts`.\n",
    "\n",
    "## Basic Neural Functional Training\n",
    "\n",
    "The most basic way to train a `NeuralFunctional` is to fit the total energy from a high accuracy calculation like full CI, CCSD, CISD etc. We will proceed using the LDA total energy we already calculated using PySCF as a \"dummy\" high accuracy calculation.\n",
    "\n",
    "We first create an optimizer for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optax import adam\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "tx = adam(learning_rate=learning_rate, b1=momentum)\n",
    "opt_state = tx.init(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and create the most basic of predictors: the non-SCF predictor. With this predictor, we assume that the charge density $\\rho(\\mathbf{r})$ passed the the Grad DFT `Molecule` object was a good approximation of the ground state density of the neural functional for all neural network parameters $\\boldsymbol{\\theta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = gd.non_scf_predictor(nf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now iterate for a number of epochs, printing out the currently predicted total energy from the `NeuralFunctional` instance and finally saving the trained model with a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:   5%|▌         | 1/20 [00:01<00:27,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 Predicted energy: -0.7769992 Cost value: 0.114921115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  15%|█▌        | 3/20 [00:01<00:07,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Predicted energy: -0.7782445 Cost value: 0.114078335\n",
      "Iteration 2 Predicted energy: -0.7794926 Cost value: 0.11323678\n",
      "Iteration 3 Predicted energy: -0.7807367 Cost value: 0.112401046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  35%|███▌      | 7/20 [00:01<00:02,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 Predicted energy: -0.7819853 Cost value: 0.11156539\n",
      "Iteration 5 Predicted energy: -0.78322804 Cost value: 0.11073674\n",
      "Iteration 6 Predicted energy: -0.78447235 Cost value: 0.109910145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  45%|████▌     | 9/20 [00:02<00:01,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 Predicted energy: -0.7857164 Cost value: 0.10908681\n",
      "Iteration 8 Predicted energy: -0.7869568 Cost value: 0.108269\n",
      "Iteration 9 Predicted energy: -0.7881994 Cost value: 0.10745279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  65%|██████▌   | 13/20 [00:02<00:00,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 Predicted energy: -0.7894391 Cost value: 0.106641605\n",
      "Iteration 11 Predicted energy: -0.7906773 Cost value: 0.105834424\n",
      "Iteration 12 Predicted energy: -0.7919148 Cost value: 0.105030775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  75%|███████▌  | 15/20 [00:02<00:00, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13 Predicted energy: -0.7931471 Cost value: 0.10423358\n",
      "Iteration 14 Predicted energy: -0.794382 Cost value: 0.10343773\n",
      "Iteration 15 Predicted energy: -0.7956114 Cost value: 0.102648444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  95%|█████████▌| 19/20 [00:02<00:00, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16 Predicted energy: -0.796839 Cost value: 0.101863325\n",
      "Iteration 17 Predicted energy: -0.7980643 Cost value: 0.1010827\n",
      "Iteration 18 Predicted energy: -0.79928565 Cost value: 0.10030756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 20/20 [00:02<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19 Predicted energy: -0.80050814 Cost value: 0.0995347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from optax import apply_updates\n",
    "\n",
    "n_epochs = 20\n",
    "for iteration in tqdm(range(n_epochs), desc=\"Training epoch\"):\n",
    "    (cost_value, predicted_energy), grads = gd.simple_energy_loss(\n",
    "        params, predictor, HH_molecule, ground_truth_energy\n",
    "    )\n",
    "    print(\"Iteration\", iteration, \"Predicted energy:\", predicted_energy, \"Cost value:\", cost_value)\n",
    "    updates, opt_state = tx.update(grads, opt_state, params)\n",
    "    params = apply_updates(params, updates)\n",
    "\n",
    "nf.save_checkpoints(params, tx, step=n_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad_dft_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
